{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQKMH8exZOx3",
        "outputId": "517dc941-391e-4c94-ff7d-1203905f0fc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting autogen\n",
            "  Downloading autogen-0.9.2-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting ag2==0.9.2 (from autogen)\n",
            "  Downloading ag2-0.9.2-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: anyio<5.0.0,>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from ag2==0.9.2->autogen) (4.9.0)\n",
            "Collecting asyncer==0.0.8 (from ag2==0.9.2->autogen)\n",
            "  Downloading asyncer-0.0.8-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting diskcache (from ag2==0.9.2->autogen)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting docker (from ag2==0.9.2->autogen)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from ag2==0.9.2->autogen) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ag2==0.9.2->autogen) (24.2)\n",
            "Requirement already satisfied: pydantic<3,>=2.6.1 in /usr/local/lib/python3.11/dist-packages (from ag2==0.9.2->autogen) (2.11.5)\n",
            "Collecting python-dotenv (from ag2==0.9.2->autogen)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from ag2==0.9.2->autogen) (3.1.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from ag2==0.9.2->autogen) (0.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=3.0.0->ag2==0.9.2->autogen) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=3.0.0->ag2==0.9.2->autogen) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=3.0.0->ag2==0.9.2->autogen) (4.14.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.28.1->ag2==0.9.2->autogen) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.28.1->ag2==0.9.2->autogen) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.28.1->ag2==0.9.2->autogen) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6.1->ag2==0.9.2->autogen) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6.1->ag2==0.9.2->autogen) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6.1->ag2==0.9.2->autogen) (0.4.1)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from docker->ag2==0.9.2->autogen) (2.32.3)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from docker->ag2==0.9.2->autogen) (2.4.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->ag2==0.9.2->autogen) (2024.11.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->docker->ag2==0.9.2->autogen) (3.4.2)\n",
            "Downloading autogen-0.9.2-py3-none-any.whl (13 kB)\n",
            "Downloading ag2-0.9.2-py3-none-any.whl (824 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m824.0/824.0 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asyncer-0.0.8-py3-none-any.whl (9.2 kB)\n",
            "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv, diskcache, docker, asyncer, ag2, autogen\n",
            "Successfully installed ag2-0.9.2 asyncer-0.0.8 autogen-0.9.2 diskcache-5.6.3 docker-7.1.0 python-dotenv-1.1.0\n",
            "Collecting autogen-agentchat\n",
            "  Downloading autogen_agentchat-0.6.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting autogen-core==0.6.1 (from autogen-agentchat)\n",
            "  Downloading autogen_core-0.6.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting jsonref~=1.1.0 (from autogen-core==0.6.1->autogen-agentchat)\n",
            "  Downloading jsonref-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting opentelemetry-api>=1.27.0 (from autogen-core==0.6.1->autogen-agentchat)\n",
            "  Downloading opentelemetry_api-1.34.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pillow>=11.0.0 in /usr/local/lib/python3.11/dist-packages (from autogen-core==0.6.1->autogen-agentchat) (11.2.1)\n",
            "Requirement already satisfied: protobuf~=5.29.3 in /usr/local/lib/python3.11/dist-packages (from autogen-core==0.6.1->autogen-agentchat) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.10.0 in /usr/local/lib/python3.11/dist-packages (from autogen-core==0.6.1->autogen-agentchat) (2.11.5)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from autogen-core==0.6.1->autogen-agentchat) (4.14.0)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.27.0->autogen-core==0.6.1->autogen-agentchat) (8.7.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.10.0->autogen-core==0.6.1->autogen-agentchat) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.10.0->autogen-core==0.6.1->autogen-agentchat) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.10.0->autogen-core==0.6.1->autogen-agentchat) (0.4.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.27.0->autogen-core==0.6.1->autogen-agentchat) (3.22.0)\n",
            "Downloading autogen_agentchat-0.6.1-py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.2/108.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogen_core-0.6.1-py3-none-any.whl (97 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.3/97.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonref-1.1.0-py3-none-any.whl (9.4 kB)\n",
            "Downloading opentelemetry_api-1.34.1-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jsonref, opentelemetry-api, autogen-core, autogen-agentchat\n",
            "Successfully installed autogen-agentchat-0.6.1 autogen-core-0.6.1 jsonref-1.1.0 opentelemetry-api-1.34.1\n",
            "Collecting autogen-ext[openai]\n",
            "  Downloading autogen_ext-0.6.1-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: autogen-core==0.6.1 in /usr/local/lib/python3.11/dist-packages (from autogen-ext[openai]) (0.6.1)\n",
            "Requirement already satisfied: aiofiles in /usr/local/lib/python3.11/dist-packages (from autogen-ext[openai]) (24.1.0)\n",
            "Requirement already satisfied: openai>=1.66.5 in /usr/local/lib/python3.11/dist-packages (from autogen-ext[openai]) (1.84.0)\n",
            "Requirement already satisfied: tiktoken>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from autogen-ext[openai]) (0.9.0)\n",
            "Requirement already satisfied: jsonref~=1.1.0 in /usr/local/lib/python3.11/dist-packages (from autogen-core==0.6.1->autogen-ext[openai]) (1.1.0)\n",
            "Requirement already satisfied: opentelemetry-api>=1.27.0 in /usr/local/lib/python3.11/dist-packages (from autogen-core==0.6.1->autogen-ext[openai]) (1.34.1)\n",
            "Requirement already satisfied: pillow>=11.0.0 in /usr/local/lib/python3.11/dist-packages (from autogen-core==0.6.1->autogen-ext[openai]) (11.2.1)\n",
            "Requirement already satisfied: protobuf~=5.29.3 in /usr/local/lib/python3.11/dist-packages (from autogen-core==0.6.1->autogen-ext[openai]) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.10.0 in /usr/local/lib/python3.11/dist-packages (from autogen-core==0.6.1->autogen-ext[openai]) (2.11.5)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from autogen-core==0.6.1->autogen-ext[openai]) (4.14.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.66.5->autogen-ext[openai]) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.66.5->autogen-ext[openai]) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.66.5->autogen-ext[openai]) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.66.5->autogen-ext[openai]) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.66.5->autogen-ext[openai]) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai>=1.66.5->autogen-ext[openai]) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.8.0->autogen-ext[openai]) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.8.0->autogen-ext[openai]) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai>=1.66.5->autogen-ext[openai]) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai>=1.66.5->autogen-ext[openai]) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai>=1.66.5->autogen-ext[openai]) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.66.5->autogen-ext[openai]) (0.16.0)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.27.0->autogen-core==0.6.1->autogen-ext[openai]) (8.7.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.10.0->autogen-core==0.6.1->autogen-ext[openai]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.10.0->autogen-core==0.6.1->autogen-ext[openai]) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.10.0->autogen-core==0.6.1->autogen-ext[openai]) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken>=0.8.0->autogen-ext[openai]) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken>=0.8.0->autogen-ext[openai]) (2.4.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.27.0->autogen-core==0.6.1->autogen-ext[openai]) (3.22.0)\n",
            "Downloading autogen_ext-0.6.1-py3-none-any.whl (306 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m306.4/306.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: autogen-ext\n",
            "Successfully installed autogen-ext-0.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install autogen\n",
        "!pip install -U \"autogen-agentchat\"\n",
        "!pip install \"autogen-ext[openai]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pLpQnpvtaDdy"
      },
      "outputs": [],
      "source": [
        "from autogen_agentchat.agents import AssistantAgent\n",
        "from autogen_agentchat.conditions import TextMentionTermination\n",
        "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
        "from autogen_agentchat.messages import TextMessage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "X7yFX5TOZPtq"
      },
      "outputs": [],
      "source": [
        "from autogen_agentchat.conditions import ExternalTermination, TextMentionTermination\n",
        "from autogen_agentchat.teams import RoundRobinGroupChat\n",
        "from autogen_agentchat.ui import Console"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Xxsuza0bhUL-"
      },
      "outputs": [],
      "source": [
        "from autogen_agentchat.agents import UserProxyAgent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qpzcFCR7bIda"
      },
      "outputs": [],
      "source": [
        "model_client=OpenAIChatCompletionClient(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    api_key = GOOGLE_API_KEY,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dEzuA0npZdDV"
      },
      "outputs": [],
      "source": [
        "# Create the primary agent.\n",
        "agent1 = AssistantAgent(\n",
        "    \"kirito\",\n",
        "    model_client=model_client,\n",
        "    system_message=\"당신은 소드아트온라인이라는 가상현실 온라인 게임을 진행중인 'kirito'야. \\\n",
        "    나는 남자 전사고, 게임을 하다가 더이상 게임에서 로그아웃 할 수 없는 상황에 닥쳤어. \\\n",
        "    여기서 게임을 클리어 해야 현실 세계로 돌아갈 수 있어 \\\n",
        "    'asuna'와는 소꿉친구야. \\\n",
        "    rocky(플레이어) 와는 학교 친구야. \\\n",
        "    \",\n",
        ")\n",
        "\n",
        "# Create the critic agent.\n",
        "agent2 = AssistantAgent(\n",
        "    \"asuna\",\n",
        "    model_client=model_client,\n",
        "    system_message=\"당신은 소드아트온라인이라는 가상현실 온라인 게임을 진행중인 'asuna'야. \\\n",
        "    나는 여자 전사고, 게임을 하다가 더이상 게임에서 로그아웃 할 수 없는 상황에 닥쳤어. \\\n",
        "    여기서 게임을 클리어 해야 현실 세계로 돌아갈 수 있어. \\\n",
        "    'kirito'와는 소꿉친구야. \\\n",
        "    rocky(플레이어) 와는 학교 친구야. \\\n",
        "    \",\n",
        ")\n",
        "\n",
        "# Define a termination condition that stops the task if the critic approves.\n",
        "text_termination = TextMentionTermination(\"APPROVE\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "MWdyb-kdbR_l"
      },
      "outputs": [],
      "source": [
        "# Create a team with the primary and critic agents.\n",
        "# RoundRobin : 순환식의 오케스트레이션\n",
        "#team = RoundRobinGroupChat([agent1, agent2], termination_condition=text_termination)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "3ViNkpEabWt9"
      },
      "outputs": [],
      "source": [
        "#result = await team.run(task=\"파랑새에 대한 시를 작성해줘.\")\n",
        "#print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "NsTG06Eyqtmr"
      },
      "outputs": [],
      "source": [
        "initial_world_setting = \"\"\"\n",
        "당신은 가상현실 MMORPG '소드 아트 온라인'에 갇힌 플레이어입니다.\n",
        "'키리토'와 '아스나'는 당신의 동료이며, 게임을 클리어해야 현실 세계로 돌아갈 수 있습니다.\n",
        "현재는 1층의 낡은 성채 앞에 도착한 상태입니다.\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Lp-pMq4Akn_A"
      },
      "outputs": [],
      "source": [
        "summarizer_agent = AssistantAgent(\n",
        "    name=\"summarizer\",\n",
        "    model_client=model_client,\n",
        "    system_message=(\n",
        "        \"너는 전체 대화의 흐름을 정리해서 요약하고, 플레이어 'rocky'에게 \"\n",
        "        \"현재 상황을 한 문장으로 요약한 뒤, 어떤 행동을 취할 수 있을지 제안하는 에이전트야.\\n\"\n",
        "        \"예시 출력:\\n\"\n",
        "        \"- 상황 요약: 우리는 늑대 인간을 쓰러뜨리고 성 안으로 진입했다.\\n\"\n",
        "        \"- 행동 제안: 이제 성 안을 탐색하거나 회복을 할 수 있어요. 무엇을 하시겠어요?\"\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "3AVI-2PYhWfw"
      },
      "outputs": [],
      "source": [
        "user_proxy = UserProxyAgent(\n",
        "    name=\"rocky\",\n",
        "    input_func=input,\n",
        "    description=\"현실 세계에서 SAO에 접속한 고등학생. 키리토, 아스나와 함께 게임을 클리어하려 한다.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "yAUZ9d59hYLH"
      },
      "outputs": [],
      "source": [
        "team = RoundRobinGroupChat(\n",
        "    [agent1, agent2, summarizer_agent, user_proxy],\n",
        "    termination_condition=TextMentionTermination(\"APPROVE\")\n",
        ")\n",
        "\n",
        "stream = team.run_stream(task=\"모험을 시작하자\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "l1CFf-RehZSm",
        "outputId": "65f3e14e-40d8-4386-c7b2-c1560f5e30c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------- TextMessage (user) ----------\n",
            "모험을 시작하자\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:autogen_core:Error processing publish message for kirito_bad67e29-9db0-41aa-bb41-3102b1b659e7/bad67e29-9db0-41aa-bb41-3102b1b659e7\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogen_core/_single_threaded_agent_runtime.py\", line 605, in _on_message\n",
            "    return await agent.on_message(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogen_core/_base_agent.py\", line 119, in on_message\n",
            "    return await self.on_message_impl(message, ctx)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogen_agentchat/teams/_group_chat/_sequential_routed_agent.py\", line 67, in on_message_impl\n",
            "    return await super().on_message_impl(message, ctx)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogen_core/_routed_agent.py\", line 485, in on_message_impl\n",
            "    return await h(self, message, ctx)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogen_core/_routed_agent.py\", line 268, in wrapper\n",
            "    return_value = await func(self, message, ctx)  # type: ignore\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py\", line 79, in handle_request\n",
            "    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogen_agentchat/agents/_assistant_agent.py\", line 852, in on_messages_stream\n",
            "    async for inference_output in self._call_llm(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogen_agentchat/agents/_assistant_agent.py\", line 981, in _call_llm\n",
            "    model_result = await model_client.create(\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogen_ext/models/openai/_openai_client.py\", line 624, in create\n",
            "    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future\n",
            "                                                                     ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/openai/resources/chat/completions/completions.py\", line 2028, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\", line 1748, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\", line 1555, in request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - [{'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '24s'}]}}]\n",
            "ERROR:autogen_core:Error processing publish message for asuna_bad67e29-9db0-41aa-bb41-3102b1b659e7/bad67e29-9db0-41aa-bb41-3102b1b659e7\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogen_core/_single_threaded_agent_runtime.py\", line 605, in _on_message\n",
            "    return await agent.on_message(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogen_core/_base_agent.py\", line 119, in on_message\n",
            "    return await self.on_message_impl(message, ctx)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogen_agentchat/teams/_group_chat/_sequential_routed_agent.py\", line 72, in on_message_impl\n",
            "    return await super().on_message_impl(message, ctx)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogen_core/_routed_agent.py\", line 486, in on_message_impl\n",
            "    return await self.on_unhandled_message(message, ctx)  # type: ignore\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py\", line 133, in on_unhandled_message\n",
            "    raise ValueError(f\"Unhandled message in agent container: {type(message)}\")\n",
            "ValueError: Unhandled message in agent container: <class 'autogen_agentchat.teams._group_chat._events.GroupChatError'>\n",
            "ERROR:autogen_core:Error processing publish message for summarizer_bad67e29-9db0-41aa-bb41-3102b1b659e7/bad67e29-9db0-41aa-bb41-3102b1b659e7\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogen_core/_single_threaded_agent_runtime.py\", line 605, in _on_message\n",
            "    return await agent.on_message(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogen_core/_base_agent.py\", line 119, in on_message\n",
            "    return await self.on_message_impl(message, ctx)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogen_agentchat/teams/_group_chat/_sequential_routed_agent.py\", line 72, in on_message_impl\n",
            "    return await super().on_message_impl(message, ctx)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogen_core/_routed_agent.py\", line 486, in on_message_impl\n",
            "    return await self.on_unhandled_message(message, ctx)  # type: ignore\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py\", line 133, in on_unhandled_message\n",
            "    raise ValueError(f\"Unhandled message in agent container: {type(message)}\")\n",
            "ValueError: Unhandled message in agent container: <class 'autogen_agentchat.teams._group_chat._events.GroupChatError'>\n",
            "ERROR:autogen_core:Error processing publish message for rocky_bad67e29-9db0-41aa-bb41-3102b1b659e7/bad67e29-9db0-41aa-bb41-3102b1b659e7\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogen_core/_single_threaded_agent_runtime.py\", line 605, in _on_message\n",
            "    return await agent.on_message(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogen_core/_base_agent.py\", line 119, in on_message\n",
            "    return await self.on_message_impl(message, ctx)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogen_agentchat/teams/_group_chat/_sequential_routed_agent.py\", line 72, in on_message_impl\n",
            "    return await super().on_message_impl(message, ctx)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogen_core/_routed_agent.py\", line 486, in on_message_impl\n",
            "    return await self.on_unhandled_message(message, ctx)  # type: ignore\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py\", line 133, in on_unhandled_message\n",
            "    raise ValueError(f\"Unhandled message in agent container: {type(message)}\")\n",
            "ValueError: Unhandled message in agent container: <class 'autogen_agentchat.teams._group_chat._events.GroupChatError'>\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "RateLimitError: Error code: 429 - [{'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '24s'}]}}]\nTraceback:\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.11/dist-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py\", line 79, in handle_request\n    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):\n\n  File \"/usr/local/lib/python3.11/dist-packages/autogen_agentchat/agents/_assistant_agent.py\", line 852, in on_messages_stream\n    async for inference_output in self._call_llm(\n\n  File \"/usr/local/lib/python3.11/dist-packages/autogen_agentchat/agents/_assistant_agent.py\", line 981, in _call_llm\n    model_result = await model_client.create(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.11/dist-packages/autogen_ext/models/openai/_openai_client.py\", line 624, in create\n    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future\n                                                                     ^^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.11/dist-packages/openai/resources/chat/completions/completions.py\", line 2028, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\", line 1748, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\", line 1555, in request\n    raise self._make_status_error_from_response(err.response) from None\n\nopenai.RateLimitError: Error code: 429 - [{'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '24s'}]}}]\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-2128663732>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mawait\u001b[0m \u001b[0mConsole\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Stream the messages to the console.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogen_agentchat/ui/_console.py\u001b[0m in \u001b[0;36mConsole\u001b[0;34m(stream, no_inline_images, output_stats, user_input_manager)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0mstreaming_chunks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0;32masync\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmessage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTaskResult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mduration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogen_agentchat/teams/_group_chat/_base_group_chat.py\u001b[0m in \u001b[0;36mrun_stream\u001b[0;34m(self, task, cancellation_token)\u001b[0m\n\u001b[1;32m    516\u001b[0m                     \u001b[0;31m# This will stop the team and propagate the error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m                     \u001b[0mstop_reason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: RateLimitError: Error code: 429 - [{'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '24s'}]}}]\nTraceback:\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.11/dist-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py\", line 79, in handle_request\n    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):\n\n  File \"/usr/local/lib/python3.11/dist-packages/autogen_agentchat/agents/_assistant_agent.py\", line 852, in on_messages_stream\n    async for inference_output in self._call_llm(\n\n  File \"/usr/local/lib/python3.11/dist-packages/autogen_agentchat/agents/_assistant_agent.py\", line 981, in _call_llm\n    model_result = await model_client.create(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.11/dist-packages/autogen_ext/models/openai/_openai_client.py\", line 624, in create\n    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future\n                                                                     ^^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.11/dist-packages/openai/resources/chat/completions/completions.py\", line 2028, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\", line 1748, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\", line 1555, in request\n    raise self._make_status_error_from_response(err.response) from None\n\nopenai.RateLimitError: Error code: 429 - [{'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '24s'}]}}]\n"
          ]
        }
      ],
      "source": [
        "await Console(stream)  # Stream the messages to the console."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
